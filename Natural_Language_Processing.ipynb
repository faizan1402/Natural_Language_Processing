{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Natural_Language_Processing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO4tyWS3vp5zH8QU4B6oSLj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/faizan1402/Natural_Language_Processing/blob/main/Natural_Language_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--oBL5RhtUEB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTG1E4gro_m7"
      },
      "source": [
        "#**Natural Language Processing Bootcamp**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBz4i5FiBNoC"
      },
      "source": [
        "#**Import spacy library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GFHYGhFBVJ-"
      },
      "source": [
        "\n",
        "import spacy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0nHvbTHBX-C"
      },
      "source": [
        "# What is Spacy?\n",
        " #Open Source natural language processing library\n",
        " # Designed to effectively nlp handle tasks with the most efficent implementation of common algorithms\n",
        "# for many NLP tasks,spacy has only one most effiecent algorithms current available\n",
        "# This means you often do n't have the option to choose other algorithms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruTRk4iqBl8O"
      },
      "source": [
        "#**Spacy Basic **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hvEW2vVBqmi"
      },
      "source": [
        "#What is NLTk?\n",
        "# > NLTK- Natural language tool kit is very popular open source\n",
        "# > Initially released in 2001 .it is much older than spacy (released 2015)\n",
        "# > It also provides many functionalities ,but includes less efficient implementaions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viBlnE_2CHcJ"
      },
      "source": [
        "# **Load the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0bseHTLCNwA"
      },
      "source": [
        "# load npl through\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-RuxIuXDR2V"
      },
      "source": [
        "#make documents\n",
        "# tokens form break -> tokens means giving any information provid \n",
        "# so spacy library through break token\n",
        "doc = nlp(u'Tesla is looking for buying U.S. based startup for $6 milion')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adTzuQ8QEF9E",
        "outputId": "b77f4262-9728-4208-81e1-c8d8fe6384be"
      },
      "source": [
        "for token in doc:\n",
        "  print(token.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla\n",
            "is\n",
            "looking\n",
            "for\n",
            "buying\n",
            "U.S.\n",
            "based\n",
            "startup\n",
            "for\n",
            "$\n",
            "6\n",
            "milion\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kBFS8pqEalz"
      },
      "source": [
        "#Part of speech check definition which defintion provide for specific word means identify noun,pronoun ..etc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fQA0HBLFkRF",
        "outputId": "bfacca9d-3afe-4ef6-c507-7a34dc0601b8"
      },
      "source": [
        "for token in doc:\n",
        "  print(token.text,token.pos)# only identify the number \n",
        "  print(\"\\n\")\n",
        "  print(token.text,token.pos_)# this line means token and part of speech break into  definition"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla 96\n",
            "\n",
            "\n",
            "Tesla PROPN\n",
            "is 87\n",
            "\n",
            "\n",
            "is AUX\n",
            "looking 100\n",
            "\n",
            "\n",
            "looking VERB\n",
            "for 85\n",
            "\n",
            "\n",
            "for ADP\n",
            "buying 100\n",
            "\n",
            "\n",
            "buying VERB\n",
            "U.S. 96\n",
            "\n",
            "\n",
            "U.S. PROPN\n",
            "based 100\n",
            "\n",
            "\n",
            "based VERB\n",
            "startup 92\n",
            "\n",
            "\n",
            "startup NOUN\n",
            "for 85\n",
            "\n",
            "\n",
            "for ADP\n",
            "$ 99\n",
            "\n",
            "\n",
            "$ SYM\n",
            "6 93\n",
            "\n",
            "\n",
            "6 NUM\n",
            "milion 92\n",
            "\n",
            "\n",
            "milion NOUN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxMsinX4Ftwv",
        "outputId": "996758ad-a976-4cba-db32-97313d18bfb2"
      },
      "source": [
        "for token in doc:\n",
        "  print(token.text,token.pos,token.dep)# dependency which words are meaning \n",
        "  print(\"\\n\")\n",
        "  print(token.text,token.pos_,token.dep_)# \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla 96 429\n",
            "\n",
            "\n",
            "Tesla PROPN nsubj\n",
            "is 87 405\n",
            "\n",
            "\n",
            "is AUX aux\n",
            "looking 100 8206900633647566924\n",
            "\n",
            "\n",
            "looking VERB ROOT\n",
            "for 85 443\n",
            "\n",
            "\n",
            "for ADP prep\n",
            "buying 100 438\n",
            "\n",
            "\n",
            "buying VERB pcomp\n",
            "U.S. 96 416\n",
            "\n",
            "\n",
            "U.S. PROPN dobj\n",
            "based 100 402\n",
            "\n",
            "\n",
            "based VERB amod\n",
            "startup 92 416\n",
            "\n",
            "\n",
            "startup NOUN dobj\n",
            "for 85 443\n",
            "\n",
            "\n",
            "for ADP prep\n",
            "$ 99 446\n",
            "\n",
            "\n",
            "$ SYM quantmod\n",
            "6 93 12837356684637874264\n",
            "\n",
            "\n",
            "6 NUM nummod\n",
            "milion 92 439\n",
            "\n",
            "\n",
            "milion NOUN pobj\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pYymPe0IAFP",
        "outputId": "446a5bb8-b22f-4000-9435-908f24191b3b"
      },
      "source": [
        "#using pipleline\n",
        "nlp.pipeline\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tagger', <spacy.pipeline.pipes.Tagger at 0x7f1fafd5cf98>),\n",
              " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x7f1fa7e35d68>),\n",
              " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f1fa7e35dc8>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODEiKD1IKHDn"
      },
      "source": [
        "#**What are the steps of NLP?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "R_f5bWPDKMew",
        "outputId": "05363024-0718-41b4-fff1-769c040b4c69"
      },
      "source": [
        "''' The five phases of NLP involve lexical (structure) analysis, \n",
        "parsing, semantic analysis, discourse integration, and pragmatic analysis. \n",
        "Some well-known application areas of NLP are Optical Character Recognition (OCR), \n",
        "Speech Recognition, Machine Translation, and Chatbots'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' The five phases of NLP involve lexical (structure) analysis, \\nparsing, semantic analysis, discourse integration, and pragmatic analysis. \\nSome well-known application areas of NLP are Optical Character Recognition (OCR), \\nSpeech Recognition, Machine Translation, and Chatbots'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kncTBeBNKbLb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji5KRy1_Kkhl"
      },
      "source": [
        "#**Building an NLP Pipeline, Step-by-Step**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "JYqqyN_8Koql",
        "outputId": "c8beb2aa-69cb-43a7-c520-45c22b6b611d"
      },
      "source": [
        "'''Step 1: Sentence Segmentation. ...\n",
        "Step 2: Word Tokenization. ...\n",
        "Step 3: Predicting Parts of Speech for Each Token. ...\n",
        "Step 4: Text Lemmatization. ...\n",
        "Step 5: Identifying Stop Words. ...\n",
        "Step 6: Dependency Parsing. ...\n",
        "Step 6b: Finding Noun Phrases. ...\n",
        "Step 7: Named Entity Recognition (NER)'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Step 1: Sentence Segmentation. ...\\nStep 2: Word Tokenization. ...\\nStep 3: Predicting Parts of Speech for Each Token. ...\\nStep 4: Text Lemmatization. ...\\nStep 5: Identifying Stop Words. ...\\nStep 6: Dependency Parsing. ...\\nStep 6b: Finding Noun Phrases. ...\\nStep 7: Named Entity Recognition (NER)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxPg-eCfxoj9"
      },
      "source": [
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lADHqFruyIJL"
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "txt2 = nlp(u\"Knowledge Shelf is n't my youtube channel.\")# u is unicode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDOMoBNIyaOH",
        "outputId": "7336ea4b-f2bc-4a00-955c-193141d6f587"
      },
      "source": [
        "for token in txt2:\n",
        "  print(token.text,token.pos_,token.dep_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Knowledge PROPN compound\n",
            "Shelf PROPN nsubj\n",
            "is AUX ROOT\n",
            "n't PART neg\n",
            "my DET poss\n",
            "youtube NOUN compound\n",
            "channel PROPN attr\n",
            ". PUNCT punct\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDfDIszIy6ro",
        "outputId": "dddc860f-64d0-4194-ca83-f047ebc18f18"
      },
      "source": [
        "txt2[0].pos "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NOYj-d54zSaF",
        "outputId": "550b9249-5341-4bac-c33b-101465bdfeb1"
      },
      "source": [
        "txt2[0].pos_ #pats of speech"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'PROPN'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nLXFdCvmzmJs",
        "outputId": "2f0f7751-0f01-44cf-f9b7-be94cde2fe7c"
      },
      "source": [
        "txt2[0].dep_# dependency"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'compound'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPPYZKaz6qLg"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rkzrlBpzuLu"
      },
      "source": [
        "txt3 = nlp(u'Although commonly attributed to John Lennon from his song \" Beautiful Boy\" , \\\n",
        "the phrase \"Life is what happens to us while we are making other plans\" was written by \\\n",
        "cartoonist Allen Saunders and published in Reader \\'s Digest in 1957,when Lennon was 17')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep057p0z8K7I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60cf4e38-4bc8-457c-b36f-7a173cdf37ff"
      },
      "source": [
        "quote = txt3[16:30]\n",
        "print(quote)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"Life is what happens to us while we are making other plans\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEAKE7WN8ifm"
      },
      "source": [
        "txt4 = nlp(u\"This is first line. This is second line.This is third line.This is last line.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiHExodH870v"
      },
      "source": [
        "# How to sentence checkup and split the sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_45bOIO9dtn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8627cd9d-fcf8-41b2-fa47-8a252c88c33d"
      },
      "source": [
        "for sentence in txt4.sents:\n",
        "  print(sentence)\n",
        "  # so spacy break the differnt line very easily formate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is first line.\n",
            "This is second line.\n",
            "This is third line.\n",
            "This is last line.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCxa0s-v-K8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e552b3d-ec33-4f00-f589-eeffe87edc0e"
      },
      "source": [
        "txt4[5].is_sent_start # so is_sent_start is a boolian value show"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTqM91eB-hem",
        "outputId": "d15837bc-3ae2-401a-b1a8-760d8d617ee7"
      },
      "source": [
        "type(quote)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.span.Span"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVft8UYv-7xC",
        "outputId": "5c1ff613-828e-4600-ec24-e8c67e56d34e"
      },
      "source": [
        "type(txt3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaKHyfS1AGtw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28117292-fa2f-49ea-cbce-8ece4045fac0"
      },
      "source": [
        "doc4 = nlp(u\"This is the first sentence . This is an other sentence.This is the last sentence.\")\n",
        "print(doc4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the first sentence . This is an other sentence.This is the last sentence.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMvDG4Gm7BCb",
        "outputId": "c2d94097-7614-49e3-920c-9e804a438b22"
      },
      "source": [
        "for sentence in doc4.sents:\n",
        "  print(sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the first sentence .\n",
            "This is an other sentence.\n",
            "This is the last sentence.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJYhatYy7DWC",
        "outputId": "cbff0259-e824-4351-a03f-e88b79de8699"
      },
      "source": [
        "doc4[6]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "This"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FLfJSI29VAO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3Gv6Ohq9V_H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnNupLGC9XD1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7i9bd4yE3bV"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_n7Y-I8Bhqx"
      },
      "source": [
        "#**Tokenization Technique**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "TbXPFjwhBrpD",
        "outputId": "318783a7-a7cc-4ad9-e21d-b775432a68e9"
      },
      "source": [
        "# Four types of analysis\n",
        "# 1-> \"We \\re moving to A.P.! \"\n",
        "'''We 're here to help! send small-mail,email knowledge-shelfitgmail.com.com or\n",
        "  visit us at https://www.knowledgeshifit.com!\n",
        "  A 5km Mumbai cab costs is INR 100.\n",
        "  Let's visit st. Louis in the U.S next year. '''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"We 're here to help! send small-mail,email knowledge-shelfitgmail.com.com or\\n  visit us at https://www.knowledgeshifit.com!\\n  A 5km Mumbai cab costs is INR 100.\\n  Let's visit st. Louis in the U.S next year. \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjD2DBCJhyuv"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L82RddoFjWVL"
      },
      "source": [
        "txt1 = '\"We\\'re moving to A.P.!\"'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cAzZbN7jkCg",
        "outputId": "9f7494c4-bc82-4bf1-a30c-6d5092454153"
      },
      "source": [
        "print(txt1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"We're moving to A.P.!\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oFDaKnQj5mv"
      },
      "source": [
        "doc = nlp(txt1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPipkJHZnnjm",
        "outputId": "014d3ec2-30a8-4387-8a09-a9bf22e35061"
      },
      "source": [
        "for token in doc:\n",
        "  print(token.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"\n",
            "We\n",
            "'re\n",
            "moving\n",
            "to\n",
            "A.P.\n",
            "!\n",
            "\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wzHP9BEoQ3w"
      },
      "source": [
        "#Spacy is a powerful tools to convert different tokens break "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc1uG-uipKVx"
      },
      "source": [
        "doc2 = nlp(\"We 're here to help! send small-mail,email knowledgeshelfit@gmail.com or visit us at https://www.knowledgeshelfit.com!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50391Y-Aql_y",
        "outputId": "c833b084-ad7b-4b91-e419-585cb3977ed5"
      },
      "source": [
        "for t in doc2:\n",
        "  print(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We\n",
            "'re\n",
            "here\n",
            "to\n",
            "help\n",
            "!\n",
            "send\n",
            "small\n",
            "-\n",
            "mail\n",
            ",\n",
            "email\n",
            "knowledgeshelfit@gmail.com\n",
            "or\n",
            "visit\n",
            "us\n",
            "at\n",
            "https://www.knowledgeshelfit.com\n",
            "!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lvlgfcGq8sa"
      },
      "source": [
        "doc3 = nlp(\"A 5km Mumbai cab ride costs is INR 100.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA2O8neB0-LF",
        "outputId": "7be04d6c-e5fa-4fe4-8479-830bdd42e1cb"
      },
      "source": [
        "for t in doc3:# so break all tokens and identify the all tokens\n",
        "  print(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A\n",
            "5\n",
            "km\n",
            "Mumbai\n",
            "cab\n",
            "ride\n",
            "costs\n",
            "is\n",
            "INR\n",
            "100\n",
            ".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5GfjMRX1Hpu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lp6BFMynpk2w"
      },
      "source": [
        "#**Natural Language Processing Bootcamp**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJpNSgpBpt9k"
      },
      "source": [
        "# .Section Goals\n",
        "# Set up spacy and Language\n",
        "# Understand basic NLP\n",
        "# > Tokenization\n",
        "# > Stemming\n",
        "# > Lemmatizations\n",
        "# > Stop Words\n",
        "# . Spacy for vocubulary matching"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5eOffSctvVG"
      },
      "source": [
        "# NLTK vs Spacy\n",
        "# > For many common NLP tasks ,spacy is much faster and more efficent at the cost of the user not being able to choose algorithmic implementations\n",
        "# > However ,Spacy does not include pre-created models for some applications,such as sentiment anlysise which is typically easier to perform with NLTK\n",
        "# In this course ,due to state of the art approach and effiecency we will focus on spacy but use NLTK when it is easier to use\n",
        "# By the end of the course,you should feel comfotable utilizing both libraries when they are best sutied for a task."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qab31Js6vGZj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hkMAfUFxr4x"
      },
      "source": [
        "#**What is Natural Language Processing?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2hK3-dix1Ft"
      },
      "source": [
        "#-> NLP is an area of computer science and artificial intelligence concerned with the interactions between computers and human (natural) languages in particular how to program computers to process and analyze large amounts of natural language data\n",
        "#-> https://en.wikipedia.org/wiki/Natura_language_processing -> website for NLP"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIG3bDxrzOM6"
      },
      "source": [
        "# ->Often when performing analysis lots of data is numerical such as sales numbers physical measuremt quantifiable categories\n",
        "#->Computers are very good at handling direct numerical information \n",
        "#->But what do we do about text about text data?\n",
        "#-> As humans we can tell there is a plethora of information inside of text documents\n",
        "#->But a computer needs specialized \"understand\" raw text data\n",
        "#->Text data is higly unstructured can be in multiple languages!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhQhshtk2FDr"
      },
      "source": [
        "#-> Natural Language Processing attemts to use a variety of techniques in order to create structure out of text data\n",
        "#-> In this section we will be discussing some of these basic techniques,which are built into libraries such as spacy and NLTK\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3akKTVw3Rwq"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rahe7ATU3bIA"
      },
      "source": [
        "#** Example Use Cases:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I0nmUNv3i3X"
      },
      "source": [
        "# -> Classifying Emails as Spam vs Legitimate\n",
        "# -> Sentiment Anlysis of Text Movie Reviews\n",
        "# -> Analyzing Trends from written customer feedback forms\n",
        "# -> Understanding text commands,\"Hey Google,Play this song.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD-7ktu2b4nl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dBASBtUcGB0"
      },
      "source": [
        "#**Natural Language Processing  Boot Camp**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "KZgcXDCXcgZc",
        "outputId": "07da20ee-f363-4931-d97b-6139232c0db8"
      },
      "source": [
        "# -> There are few keys steps for working with spacy that we will cover in this lecture :\n",
        "# -> Loading the language library \n",
        "# -> Building a pipeline object\n",
        "# -> Using Tokens\n",
        "# -> Understanding token attributes\n",
        "# -> The nlp function from spacy autometically takes raw text and performs a series of operation to tag,parse,and describe the text data.\n",
        "# -> Let's discover the pipeline object and its series of operations.\n",
        "# -> In subsequent lectures drive deeper into each these aspects of nlp and spacy (e.g. tokenization,Pos stemming,Lemmatization,etc)\n",
        "\n",
        "\n",
        "# Tag                   Description                                                                       doc2[0].tag\n",
        "'''\n",
        ".text                   The original word text                                                              Tesla\n",
        ".lemma                  The base form of the word                                                            tesla                       \n",
        ".pos_                   The simple part-of-speech tag                                                      PROPN/proper noun     \n",
        ".tag_                    The detailed part-of-speech tag                                                   NNP/ noun,proper singular\n",
        ".shape_                  The word shape-captialization,punction,digits                                        Xxxxx\n",
        ".is_alpha                Is the token an alpha character                                                     True\n",
        ".is_stop                 Is the token of a stop list,i.e the most common words of the language?               False '''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n.text                   The original word text                                                              Tesla\\n.lemma                  The base form of the word                                                            tesla                       \\n.pos_                   The simple part-of-speech tag                                                      PROPN/proper noun     \\n.tag_                    The detailed part-of-speech tag                                                   NNP/ noun,proper singular\\n.shape_                  The word shape-captialization,punction,digits                                        Xxxxx\\n.is_alpha                Is the token an alpha character                                                     true\\n.is_stop                 Is the token of a stop list,i.e the most common words of the language?               False '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVyqUXV7tI_K"
      },
      "source": [
        " # https://spacy.io/api/annotation#pos-tagging\n",
        "  # Thir url for spacy  and check diiferent language and functionalaity and description\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUn65Gj129H7"
      },
      "source": [
        "# Tokenization : Tokens are the basic building blocks of a Doc object-everything that helps us understanding the meaning of the text is derived from tokens and their relationship to one another.\n",
        "# Prefix : Character(s)at the beginning  Example -> $(\"\")\n",
        "#Suffix : Character(s) at the end  Example -> km),.!\"\n",
        "# Infix : Character(s) in between Example -> - --/...\n",
        "# Exception : Special-case rule to split a string into several being split when punctuation rules are applied Example -> let's u.s\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAcQjcspI96l"
      },
      "source": [
        "# Tokens have a variety of useful attributes and methods.\n",
        "#  Let's explore tokens with spacy in furt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh6svLl0wshL"
      },
      "source": [
        "doc5 = nlp(u\"It is better to give than recieve .\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEUKH45xw7C5",
        "outputId": "289fdc62-fa28-45f3-c13c-7ff1edefa07a"
      },
      "source": [
        "doc5[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "It"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dlv1p2ux46p",
        "outputId": "ed3017c4-98af-48a3-ac95-6856d3c22249"
      },
      "source": [
        "doc5[2:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "better to give"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmbPwvh0yCDe"
      },
      "source": [
        "doc6 = nlp(u\"Apple build a Hongkong factory for $6 milion\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3v6LjYWsy3vf",
        "outputId": "82a1eaba-e52a-4f09-b031-43a98b4de295"
      },
      "source": [
        "for token in doc6 :\n",
        "  print(token.text,end=' | ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple | build | a | Hongkong | factory | for | $ | 6 | milion | "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcpdxxtqzB1L",
        "outputId": "543a7953-099f-47c2-865c-5e9e657dfafe"
      },
      "source": [
        "# How to entity recognized text,number and special symbol\n",
        "for entity in doc6.ents:\n",
        "  print(entity)\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple\n",
            "Hongkong\n",
            "$6 milion\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnW9kUiw0Gmc",
        "outputId": "ed919a18-3ed2-47e0-cca8-313390ea7922"
      },
      "source": [
        "for entity in doc6.ents:\n",
        "   print(entity) # this function to recognize entity \n",
        "   print(entity.label_)\n",
        "   print(str(spacy.explain(entity.label_)))# means print every words of meaning generate spacy libraries and very important this libraries in NLP (so spacy provide a particular words)\n",
        "   print('\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple\n",
            "ORG\n",
            "Companies, agencies, institutions, etc.\n",
            "\n",
            "\n",
            "Hongkong\n",
            "GPE\n",
            "Countries, cities, states\n",
            "\n",
            "\n",
            "$6 milion\n",
            "MONEY\n",
            "Monetary values, including unit\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZXmmMSW0LYk"
      },
      "source": [
        "doc8 = nlp(u\"Autonomous cars shift insurence liability toward manufacturess\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScHSTsJG2_wP",
        "outputId": "841cf373-fa48-42fb-f30b-0006de095353"
      },
      "source": [
        "# Print noun chunks\n",
        "for chunk in doc8.noun_chunks:\n",
        "  print(chunk)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Autonomous cars\n",
            "insurence liability\n",
            "manufacturess\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmZCHw983Hb8"
      },
      "source": [
        "# displacy -> displacy is the actual visuliser real cool awesome inside notebook and create take data server and outside the notebook or inside both are run.\n",
        "from spacy import displacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90e8lgTr5Or8"
      },
      "source": [
        "doc = nlp(u\"Apple is going to build a U.K. factory for $6 milion.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "_mSHWtym5zzF",
        "outputId": "2493f3f3-e050-49f2-96bb-6b24969c3438"
      },
      "source": [
        "displacy.render(doc,style='dep',jupyter = True,options = {'distance':60}) #and changed the distance 110\n",
        "# Syntatic display "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"f72fca57b9e44d9c8318f506ced2f037-0\" class=\"displacy\" width=\"770\" height=\"257.0\" direction=\"ltr\" style=\"max-width: none; height: 257.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"167.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"167.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"110\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"110\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"167.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"170\">going</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"170\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"167.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">to</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"167.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"290\">build</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"290\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"167.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"167.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">U.K.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"167.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"470\">factory</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"470\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"167.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"530\">for</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"530\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"167.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">$</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">SYM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"167.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">6</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"167.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">milion.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f72fca57b9e44d9c8318f506ced2f037-0-0\" stroke-width=\"2px\" d=\"M70,122.0 C70,62.0 160.0,62.0 160.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f72fca57b9e44d9c8318f506ced2f037-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,124.0 L62,112.0 78,112.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f72fca57b9e44d9c8318f506ced2f037-0-1\" stroke-width=\"2px\" d=\"M130,122.0 C130,92.0 155.0,92.0 155.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f72fca57b9e44d9c8318f506ced2f037-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M130,124.0 L122,112.0 138,112.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f72fca57b9e44d9c8318f506ced2f037-0-2\" stroke-width=\"2px\" d=\"M250,122.0 C250,92.0 275.0,92.0 275.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f72fca57b9e44d9c8318f506ced2f037-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M250,124.0 L242,112.0 258,112.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f72fca57b9e44d9c8318f506ced2f037-0-3\" stroke-width=\"2px\" d=\"M190,122.0 C190,62.0 280.0,62.0 280.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f72fca57b9e44d9c8318f506ced2f037-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M280.0,124.0 L288.0,112.0 272.0,112.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f72fca57b9e44d9c8318f506ced2f037-0-4\" stroke-width=\"2px\" d=\"M370,122.0 C370,62.0 460.0,62.0 460.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f72fca57b9e44d9c8318f506ced2f037-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M370,124.0 L362,112.0 378,112.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f72fca57b9e44d9c8318f506ced2f037-0-5\" stroke-width=\"2px\" d=\"M430,122.0 C430,92.0 455.0,92.0 455.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f72fca57b9e44d9c8318f506ced2f037-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M430,124.0 L422,112.0 438,112.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f72fca57b9e44d9c8318f506ced2f037-0-6\" stroke-width=\"2px\" d=\"M310,122.0 C310,32.0 465.0,32.0 465.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f72fca57b9e44d9c8318f506ced2f037-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M465.0,124.0 L473.0,112.0 457.0,112.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f72fca57b9e44d9c8318f506ced2f037-0-7\" stroke-width=\"2px\" d=\"M310,122.0 C310,2.0 530.0,2.0 530.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f72fca57b9e44d9c8318f506ced2f037-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M530.0,124.0 L538.0,112.0 522.0,112.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f72fca57b9e44d9c8318f506ced2f037-0-8\" stroke-width=\"2px\" d=\"M610,122.0 C610,92.0 635.0,92.0 635.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f72fca57b9e44d9c8318f506ced2f037-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M610,124.0 L602,112.0 618,112.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f72fca57b9e44d9c8318f506ced2f037-0-9\" stroke-width=\"2px\" d=\"M670,122.0 C670,92.0 695.0,92.0 695.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f72fca57b9e44d9c8318f506ced2f037-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M670,124.0 L662,112.0 678,112.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f72fca57b9e44d9c8318f506ced2f037-0-10\" stroke-width=\"2px\" d=\"M550,122.0 C550,32.0 705.0,32.0 705.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f72fca57b9e44d9c8318f506ced2f037-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M705.0,124.0 L713.0,112.0 697.0,112.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXhG5Ba26UY7"
      },
      "source": [
        "doc = nlp(u\"Over the last quarter Apple sold nearly 20 thousand iPods for $6 milion.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "CBmrXM_o8BOr",
        "outputId": "00fa6af6-bbe6-464d-8fe9-8d03ac06954d"
      },
      "source": [
        "# displacy entity in jupyter notebook\n",
        "displacy.render(doc,style='ent',jupyter=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the last quarter\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Apple\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " sold \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    nearly 20 thousand\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    iPods\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
              "</mark>\n",
              " for \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    $6 milion\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              ".</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_OYjam_8cbk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S81onyuH-CEp"
      },
      "source": [
        "#**Creating visualizations outside the jupyter **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmadIDUy-T3p",
        "outputId": "04242b60-5e75-464b-bedf-ff537c947c8b"
      },
      "source": [
        "# How to create entity outside the server\n",
        "doc = nlp(u\"This is a sentence.\")\n",
        "displacy.serve(doc,style='dep')# dep->dependency"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using the 'dep' visualizer\n",
            "Serving on http://0.0.0.0:5000 ...\n",
            "\n",
            "Shutting down server on port 5000.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4OKHTzX_ESO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jozx6DcvAugL"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn7wIrYaA25n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iytPF-a7A4D-"
      },
      "source": [
        "#**Stemming in NLP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OfK79adBDd_"
      },
      "source": [
        "# Stemming : Often when searching text for a certain keyword ,it help if the search returns  variations of the word.\n",
        "# For instance,searching for \"boat\" might also return \"boats\" and \"boating\".Here \"boat\" would be the stem for[boat,boater,boating,boats].\n",
        "# Stemming is a somewhat crude method for cataloging related words; it essentially chops off letters from the end until the stem is reached .\n",
        "# This works fairly well in most cases but unfortunately English has many exceptions where a more sophisticated process is required.\n",
        "# In fact spacy does n't include a stemmer opting instead to rely entirely on lemmatization.\n",
        "# There is a lin in the notebook to a discussion on the manintainers of spacy deciding on not including a stemmer (in favor of lemmatization)\n",
        "# Because of this decision to not include  stemming in spacy ,we will jump over to using NLTK and learn about various Stemmers.\n",
        "# We'll show both the porter Stemmer and the snowball Stemmer.\n",
        "# In the first phase ,simple suffix mapping rules are defined,such as:\n",
        "# Snowball is the name of a stemming language also developed by Martin Porter.\n",
        "# The Algorithm used here is more accurately called the \"English Stemmer\" or \"Porter2 Stemmer\".\n",
        "# It offers a slight improvements over the original Porter stemmer,noth in logic and speed.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9VVDnfqHv2C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kdn7SDHzHz9z"
      },
      "source": [
        "#**Install NLTK:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfcPSUmMHw97"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIIpTgKVHxVv"
      },
      "source": [
        "from nltk.stem.porter import PorterStemmer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIDtg2UeIIKK"
      },
      "source": [
        "p_stemmer = PorterStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9X7XGIRIQTj"
      },
      "source": [
        "words = ['run','runner','ran','runs','easily','fairly','fairness', 'laughing','good looking' ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rXQHrMlIg_w",
        "outputId": "8e4f7f10-7aaa-480c-e0df-2848352ef2e0"
      },
      "source": [
        "for word in words:\n",
        "  print(word + '----->' + p_stemmer.stem(word))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run----->run\n",
            "runner----->runner\n",
            "ran----->ran\n",
            "runs----->run\n",
            "easily----->easili\n",
            "fairly----->fairli\n",
            "fairness----->fair\n",
            "laughing----->laugh\n",
            "good looking----->good look\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBFHVHbqJFGD"
      },
      "source": [
        "from nltk.stem.snowball import SnowballStemmer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaL-oc8JJ6NZ"
      },
      "source": [
        "s_stemmer = SnowballStemmer(language='english')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ_eMG_WKH68",
        "outputId": "f5022fb5-b481-46fb-d555-769ff9e14ac5"
      },
      "source": [
        "for word in words:\n",
        "  print(word + '  ------> '  + s_stemmer.stem(word))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run  ------> run\n",
            "runner  ------> runner\n",
            "ran  ------> ran\n",
            "runs  ------> run\n",
            "easily  ------> easili\n",
            "fairly  ------> fair\n",
            "fairness  ------> fair\n",
            "laughing  ------> laugh\n",
            "good looking  ------> good look\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkLpEY3AK2Ir"
      },
      "source": [
        "words = ['generous','generation','generously','generate']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KcVNkAnMwqi",
        "outputId": "2b0a1ec3-6cde-4257-e4f1-79419fd634d0"
      },
      "source": [
        "for word in words:\n",
        "  print(word +  '   -------> ' + s_stemmer.stem(word))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "generous   -------> generous\n",
            "generation   -------> generat\n",
            "generously   -------> generous\n",
            "generate   -------> generat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpu1odYFNGBF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIx8_b-PTHRr"
      },
      "source": [
        "#**Lemmatization:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuM8D8SZTP-J"
      },
      "source": [
        "# In contrast to stemming ,lemmatization looks beyond word reduction,and  consideres a languages  full vocubulary to apply a morphological analysis to words.\n",
        "# The lemma of was is be and the lemma of meeting might be meet or meeting depending on its use in a sentence.\n",
        "# Lemmatizations is typically seen as much more information than simple stemming,which is why spacy has opted to only have Lemmatization available instead of Stemming.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9oRqCAkWVFp"
      },
      "source": [
        "import spacy "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7lzPPq6WWZp"
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t975JB_kWkke"
      },
      "source": [
        "doc1 = nlp(u\"I am a runner running in a race because I love to run since I ran today\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skSpZxxDXusn",
        "outputId": "a80027cd-3392-47c9-8338-fd25f7b457b1"
      },
      "source": [
        "#token.text->Simple text break in tokens form,toke.pos-> part of speech,token.lemma-> hash code formation\n",
        "for token in doc1:\n",
        "  print(token.text,'\\t',token.pos_,'\\t',token.lemma,'\\t',token.lemma_)\n",
        "# 561228191312463089  -> so below between show the hash refrence and hash  code"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I \t PRON \t 561228191312463089 \t -PRON-\n",
            "am \t AUX \t 10382539506755952630 \t be\n",
            "a \t DET \t 11901859001352538922 \t a\n",
            "runner \t NOUN \t 12640964157389618806 \t runner\n",
            "running \t VERB \t 12767647472892411841 \t run\n",
            "in \t ADP \t 3002984154512732771 \t in\n",
            "a \t DET \t 11901859001352538922 \t a\n",
            "race \t NOUN \t 8048469955494714898 \t race\n",
            "because \t SCONJ \t 16950148841647037698 \t because\n",
            "I \t PRON \t 561228191312463089 \t -PRON-\n",
            "love \t VERB \t 3702023516439754181 \t love\n",
            "to \t PART \t 3791531372978436496 \t to\n",
            "run \t VERB \t 12767647472892411841 \t run\n",
            "since \t SCONJ \t 10066841407251338481 \t since\n",
            "I \t PRON \t 561228191312463089 \t -PRON-\n",
            "ran \t VERB \t 12767647472892411841 \t run\n",
            "today \t NOUN \t 11042482332948150395 \t today\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bi02wf7YL-O"
      },
      "source": [
        "# Using function ->def function\n",
        "def show_lemmas(text):\n",
        "  for token in text:\n",
        "    print(f'{token.text:{12}} {token.pos_:{6}}  {token.lemma:<{22}} {token.lemma_}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpoUNQD5a91c"
      },
      "source": [
        "doc2 = nlp(u\"I saw ten mice today!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jOGYVmkbcab",
        "outputId": "8b70c3ef-2f2d-4291-e70e-5836a8662a28"
      },
      "source": [
        "show_lemmas(doc2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I            PRON    561228191312463089     -PRON-\n",
            "saw          VERB    11925638236994514241   see\n",
            "ten          NUM     7970704286052693043    ten\n",
            "mice         NOUN    1384165645700560590    mouse\n",
            "today        NOUN    11042482332948150395   today\n",
            "!            PUNCT   17494803046312582752   !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mahne4j6bs5t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OH4qziNe2Vf"
      },
      "source": [
        "#**Stop Words in NLP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "N9ZyuEwie7A9",
        "outputId": "9da58531-a198-410d-986f-259bf0bbfff5"
      },
      "source": [
        "''' -> words like \"a\" and \"the\" appear so frequently that they do n't require tagging as throughly as nouns,verbs and modifiers.\n",
        " -> We call these stop words ,and they can be filtered from the text to be processed.\n",
        " -> Spacy holds a built-in list of some 305 English stop words.'''\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' -> words like \"a\" and \"the\" appear so frequently that they do n\\'t require tagging as throughly as nouns,verbs and modifiers.\\n -> We call these stop words ,and they can be filtered from the text to be processed.\\n -> Spacy holds a built-in list of some 305 English stop words.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQrDrlPLgZev"
      },
      "source": [
        " import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ievzkjudgfmk"
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w98EmMCFgtuP",
        "outputId": "0d43926b-43b3-4b8b-98f4-b8975886145d"
      },
      "source": [
        "print(nlp.Defaults.stop_words)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'somewhere', 'ca', 'whether', 'alone', 'above', 'am', 'same', 'towards', 'hereafter', 'out', 'too', 'seemed', 'by', 'thence', 'him', 'just', 'everywhere', 'side', 'somehow', 'own', 'namely', 'then', 'off', 'three', 'anything', 'because', 'twelve', 'beyond', 'someone', 'we', 'he', 'mine', 'really', 'due', 'his', 'myself', 'seeming', 'her', 'becomes', 'whereafter', 'yourself', '‘m', 'afterwards', 'still', 'move', 'whose', 'would', 'thus', 'besides', 'did', 'was', 'hence', 'whence', 'please', 'whenever', 'which', 'meanwhile', 'done', 'as', 'into', 'thru', 'latterly', 'beside', 'elsewhere', 'former', 'further', 'fifty', \"'re\", '‘re', 'various', 'well', 'rather', 'though', 'about', 'almost', 'but', 'himself', 'together', 'will', 'something', 'whom', 'until', 'used', 'another', 'upon', 'using', \"'ll\", \"'d\", 'ten', 'others', '’m', '‘ve', 'except', 'get', 'sometimes', 'them', 'at', 'seems', 'whither', 'our', 'hundred', 'may', 'seem', 'go', 'bottom', 'how', 'indeed', 'each', 'otherwise', 'up', 'anyhow', 'itself', 'without', 'one', \"'m\", 'nevertheless', 'can', 'that', 'under', '’re', 'formerly', 'everything', 'once', 'anyone', 'unless', 'yet', 'neither', 'a', 'cannot', 'do', 'regarding', 'amongst', 'for', 'an', 'also', 'might', 'does', 'nine', 'herself', 'were', 'give', 'most', 'throughout', 're', 'whatever', 'whereupon', 'between', \"'ve\", 'or', 'more', 'every', 'first', 'ever', 'onto', 'put', 'herein', 'became', 'sixty', 'the', 'there', 'where', 'wherein', 'any', 'sometime', 'could', 'moreover', 'mostly', 'than', 'thereafter', 'being', 'had', 'often', 'beforehand', 'and', 'in', 'therefore', 'become', '’d', 'top', 'anyway', 'per', 'their', 'nor', 'what', '‘ll', 'over', 'who', 'yourselves', 'n‘t', 'nowhere', 'becoming', 'everyone', 'when', 'wherever', 'been', 'is', 'some', 'if', 'nothing', 'hers', 'within', 'along', 'such', 'see', 'serious', 'again', 'among', 'nobody', 'whereby', 'make', 'take', 'hereby', '’s', 'all', 'they', 'even', 'has', '’ll', 'below', 'down', 'hereupon', 'least', 'six', 'it', 'after', 'are', 'else', 'much', 'no', 'me', 'none', 'latter', 'made', 'however', 'show', 'themselves', 'anywhere', 'across', 'two', 'whereas', 'while', \"'s\", 'enough', 'although', 'thereby', '‘d', 'therein', 'already', 'not', 'only', 'never', 'so', 'n’t', 'many', 'back', 'my', 'empty', 'five', 'quite', 'both', 'on', 'its', '‘s', 'around', 'be', 'ourselves', 'eleven', 'part', 'i', 'via', 'should', 'several', 'here', 'your', 'now', 'few', 'amount', 'thereupon', 'whole', 'four', 'last', 'you', '’ve', 'since', 'noone', 'very', 'ours', 'front', 'fifteen', 'call', 'other', 'before', 'she', 'why', 'with', 'this', 'to', 'toward', 'doing', 'always', 'either', 'keep', 'third', 'full', 'must', 'behind', 'less', 'forty', 'have', 'name', 'these', 'through', 'perhaps', 'us', 'those', 'yours', \"n't\", 'next', 'from', 'whoever', 'during', 'eight', 'say', 'of', 'against', 'twenty'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7etaTFo4hDQ2"
      },
      "source": [
        "# And these words to stop problems to spacy finding time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSYf46LJiAJr",
        "outputId": "14669a27-412d-44b1-bd09-a089327a8e73"
      },
      "source": [
        "# Check nlp stop length\n",
        "len(nlp.Defaults.stop_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "326"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLmtEgtsiNTP",
        "outputId": "10ed54a2-58cc-4b4b-e294-41431d52c81e"
      },
      "source": [
        "#Suppose which vocubalary to stop then\n",
        "nlp.vocab['is'].is_stop"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUEeAKBdi7O9",
        "outputId": "98f415fc-fe0c-4e84-c76c-b8c4bd481581"
      },
      "source": [
        "#But suppose unique words then not stop words then false\n",
        "nlp.vocab['mystery'].is_stop"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8gX8ttDkPaE",
        "outputId": "b6fef51c-40d5-42e9-86d0-8708316a2428"
      },
      "source": [
        "# How to extra words in stop words\n",
        "nlp.Defaults.stop_words.add('btw')\n",
        "nlp.vocab['btw'].is_stop = True\n",
        "len(nlp.Defaults.stop_words)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "327"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s85pEZWelMPx",
        "outputId": "dae9f391-7feb-4e7e-da4b-90d0bc32cdfc"
      },
      "source": [
        "nlp.vocab['btw'].is_stop\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tnj1kchfl7Tb"
      },
      "source": [
        "#If remove stop words from original set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oeMte5tmmj9"
      },
      "source": [
        "nlp.Defaults.stop_words.remove('beyond')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl8-MDDanI5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "f364ba61-57d5-496b-e0ce-e0b6cf1767b7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-07be5ff4bce8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'stop_words' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81mqNmmJvOBn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}