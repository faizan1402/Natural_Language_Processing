{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Feature_Extraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Ep8JlIAM-2kqHmErnaU79zXxicOnXQa4",
      "authorship_tag": "ABX9TyMU6wF4rRbnxV/OMaV1VFOn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/faizan1402/Natural_Language_Processing/blob/main/Text_Feature_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOMff_PLTE3K"
      },
      "source": [
        "# Most classic machine learning algorithms can n't take in ran text.\r\n",
        "# Instead we need to perform a feature \"extraction\" from the raw text in order to pass numerical features to the machine learning algorithm.\r\n",
        "# For example,we could count the occurence of each word to map text to a number.\r\n",
        "# Let's discuss counter vectorization along with term-frequency and inverse\r\n",
        "# Document Frequency"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cJ7vTneVFs-"
      },
      "source": [
        "#Count Vectorization -\r\n",
        " #messages = [\"Hey,lets go to the game today!\",\"call your sister.\",\"want to go walk your dogs?\"]\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "vect = CountVectorizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLcxv5aYVGCa"
      },
      "source": [
        "# Document Term Matrix (DTM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "O4TEnLXiVGT6",
        "outputId": "97e757e3-39b3-4ac3-a82c-c02de8e88971"
      },
      "source": [
        "'''\r\n",
        "\r\n",
        "An alternative to countVectorization is something called TfidfVectrorization is also creates a document term matrix from our messages.\r\n",
        "-> However ,instead of filling the DTM with token counts it calculates term frequency-inverse document frequency value for each word (TF-IDF)\r\n",
        "-> term frequency tf(t,d) is the raw count of a times that term to occurs in document d.\r\n",
        "-> However,Term Frequency alone is n't enough for a through features analysis of the text!\r\n",
        "-> Let's imagine very common terms,like \"a\" or \"the\"...\r\n",
        "\r\n",
        "-> Because the term \"the is so common,term frequency will tend to incorrectly emphasize documents which happen to use the word \"the\" more frequently,without giving enough \r\n",
        "   weight to the more meaningful terms \"red\" and \"dogs\".\r\n",
        "-> Inverse documents frequency factor is incorporated which diminishes the weight of terms that occur very frequently in the document set and increases the weight of \r\n",
        "    terms that occur rarely.\r\n",
        "->  It is the logarithmically scaled inverse fraction of the documents that contain word (objtained by dividing the total number of documents by the number of documents containing the term,and then taking the logarithm of that quotient)\r\n",
        " -> Fortunately Scikit-learn can calculate all these terms for us through the use of API.\r\n",
        " -> Notice how similar the syntax is to our previous use of ML models in SciKit- Learn!\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "'''\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nAn alternative to countVectorization is something called TfidfVectrorization is also creates a document term matrix from our messages.\\n-> However ,instead of filling the DTM with token counts it calculates term frequency-inverse document frequency value for each word (TF-IDF)\\n-> term frequency tf(t,d) is the raw count of a times that term to occurs in document d.\\n-> However,Term Frequency alone is n\\'t enough for a through features analysis of the text!\\n-> Let\\'s imagine very common terms,like \"a\" or \"the\"...\\n\\n-> Because the term \"the is so common,term frequency will tend to incorrectly emphasize documents which happen to use the word \"the\" more frequently,without giving enough \\nweight to the more meaningful terms \"red\" and \"dogs\".\\n-> Inverse documents frequency factor is incorporated which diminishes the weight of terms that occur very frequently in the document set and increases the weight of \\nterms that occur rarely.\\n-> It is the logarithmically scaled inverse fraction of the documents that contain word (objtained by dividing the total number of documents by the number of documents containing the term,and then taking the logarithm of that quotient)\\n -> Fortunately Scikit-learn can calculate all these terms for us through the use of API.\\n -> Notice how similar the syntax is to our previous use of ML models in SciKit- Learn!\\n\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajc5me6yZ2IT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y9O8fMLclXi"
      },
      "source": [
        "#**Start with some documents:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DirHbHvMVGje",
        "outputId": "fe48f87e-8564-4790-f5bd-6c4369a4c77f"
      },
      "source": [
        "%%writefile 1.txt\r\n",
        "This is a story about cats\r\n",
        "our feline pets\r\n",
        "Cats are furry animals\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting 1.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8ThXKdqhJt6",
        "outputId": "64109ee3-6c8b-45be-de0e-6c17b2151294"
      },
      "source": [
        "%%writefile 2.txt\r\n",
        "This story is about suffering\r\n",
        "Catching waves is fun\r\n",
        "Surfing is a popular water sport "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting 2.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6jQIZnHdiK1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrfamNdOd9hP"
      },
      "source": [
        "#**Build a vocabulary:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8Rd1Eiidi4C",
        "outputId": "01339739-feb5-4114-c607-51af99ae892e"
      },
      "source": [
        "vocab = {} #format dictionary order\r\n",
        "i =1\r\n",
        "\r\n",
        "with open('1.txt') as f:\r\n",
        "     x = f.read().lower().split()# lower order read the txt\r\n",
        "for word in x:\r\n",
        "    if word in vocab:\r\n",
        "       continue\r\n",
        "    else:\r\n",
        "        vocab[word] = i# assign to unique id \r\n",
        "        i+=1\r\n",
        "print(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'this': 1, 'is': 2, 'a': 3, 'story': 4, 'about': 5, 'cats': 6, 'our': 7, 'feline': 8, 'pets': 9, 'are': 10, 'furry': 11, 'animals': 12}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gisP-Hxtdjd3",
        "outputId": "29024011-0533-4050-b925-f7a6515b9778"
      },
      "source": [
        "with open('2.txt') as f:\r\n",
        "  x = f.read().lower().split()\r\n",
        "for word in x:\r\n",
        "  if word in vocab:\r\n",
        "    continue\r\n",
        "  else:\r\n",
        "    vocab[word] = i\r\n",
        "    i+=1\r\n",
        "print(vocab)\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'this': 1, 'is': 2, 'a': 3, 'story': 4, 'about': 5, 'cats': 6, 'our': 7, 'feline': 8, 'pets': 9, 'are': 10, 'furry': 11, 'animals': 12, 'suffering': 13, 'catching': 14, 'waves': 15, 'fun': 16, 'surfing': 17, 'popular': 18, 'water': 19, 'sport': 20}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az34TRSNdkoo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fql-gb2ViHsc"
      },
      "source": [
        "#**Feature Extraction :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdE_Vvf5dlDg"
      },
      "source": [
        "#Now that we 've encapsulated our entire language\" in a dictionary.let's perform feature extraction on each of our original documents."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GugYlRqai3C4",
        "outputId": "7aee8a38-ded4-48b5-ba1a-65b7d0145cd4"
      },
      "source": [
        "# create ath empty vector with space for each word in the vocabulary:\r\n",
        "one = ['1.txt'] +[0]*len(vocab)\r\n",
        "one"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1.txt', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yoct01ujKu-",
        "outputId": "ff6b836a-db7d-40a8-a973-adce043506c9"
      },
      "source": [
        "# map the frequencies of each word in 1.txt to our vector:\r\n",
        "with open('1.txt') as f:\r\n",
        "    x = f.read().lower().split()\r\n",
        "for word in x:\r\n",
        "  one[vocab[word]]+=1\r\n",
        "one"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1.txt', 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6_lQq9Hj3Q0"
      },
      "source": [
        "# Do the same for the second document:\r\n",
        "two = ['2.txt']+[0]*len(vocab)\r\n",
        "\r\n",
        "with open('2.txt') as f:\r\n",
        "  x = f.read().lower().split()\r\n",
        "\r\n",
        "for word in x:\r\n",
        "   two[vocab[word]]+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6TfdYiklYm5",
        "outputId": "f9ddd17f-fceb-46f6-af88-6811dd3d46dd"
      },
      "source": [
        "# Compare the two vectors:\r\n",
        "print(f'{one}\\n{two}')\r\n",
        "'''\r\n",
        "By comparing the vectors we see that some words are common to both ,some appear only in 1.txt,others only 2.txt. Extending this logic to tens of thousands of \r\n",
        "documents,we would see the vocabulary dictionary grow to hundreds,of thousands of words.\r\n",
        "Vectors would contain mostly zero values them sparse matrices.\r\n",
        "\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1.txt', 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "['2.txt', 1, 3, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmTeUIvulmOg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPd3WJDEnTPd"
      },
      "source": [
        "#**Bag of Words and Tf-idf**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhYFB0AknaEH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7-pHHUunfAA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEhrAx7gngmv"
      },
      "source": [
        "#**Stop Words and Word Stems**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN_ULdpKnfMU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgzHuebMnfW3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3adfXK3nfhd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ei5Y7RP2nq7r"
      },
      "source": [
        "#**Tokenization and Tagging**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nVYnFvynwDa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUu4i0Yrn-M_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsZIAISOoHY-"
      },
      "source": [
        "#**Feature Extraction from Text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEt14pA2n-oO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a9b044f7-97d3-4ca6-ea67-be81d0fcc96b"
      },
      "source": [
        "# Count Vectorization\r\n",
        "  # messages = [\"Hey lets go to the game today!\",\"call your sister.\",\" want to go walk your dogs?\"]\r\n",
        "\r\n",
        " # from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "  #vect = CountVectorizer()\r\n",
        "\r\n",
        "'''-> An alternative to countvectorizer is something called TfidVectorizer is also\r\n",
        "creates a document term matrix messages.'''\r\n",
        "\r\n",
        "'''-> However ,instead of filling the DTM with token counts it calculates trtm\r\n",
        "frequency- inverse document frequency value for each word (TF-IDF)'''\r\n",
        "\r\n",
        "'''-> Term frequency tf(t,d) is the raw count of term in a document,i.e the number of \r\n",
        "times that term t occurs in document d.'''\r\n",
        "\r\n",
        "'''-> A basic manual implementation building a vocabulary \r\n",
        "-> Using SciKit - learn for vectorization\r\n",
        "-> Using Pipelines wiht Scikit- Learn'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'-> A basic manual implementation building a vocabulary \\n-> Using SciKit - learn for vectorization\\n-> Using Pipelines wiht Scikit- Learn'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjI1EAIxoAHP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b96072e8-2b0a-4716-8384-5fae28b0206f"
      },
      "source": [
        "from google.colab import drive\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "drive.mount('/content/drive')\r\n",
        "file_url = '/content/drive/MyDrive/UPDATED_NLP_COURSE/UPDATED_NLP_COURSE/TextFiles/smsspamcollection.tsv'\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "WUsEyDlqGLH8",
        "outputId": "c342786f-96cc-4af3-8467-e8b3f446e677"
      },
      "source": [
        "df = pd.read_csv(file_url,sep = '\\t')\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "      <th>length</th>\n",
              "      <th>punct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>111</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>29</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>155</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>49</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>61</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                            message  length  punct\n",
              "0   ham  Go until jurong point, crazy.. Available only ...     111      9\n",
              "1   ham                      Ok lar... Joking wif u oni...      29      6\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155      6\n",
              "3   ham  U dun say so early hor... U c already then say...      49      6\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...      61      2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7SDvxaQ-6TO",
        "outputId": "b8ddd59c-be79-42df-c9b5-48116fc60ff5"
      },
      "source": [
        "df.isnull().sum"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.sum of       label  message  length  punct\n",
              "0     False    False   False  False\n",
              "1     False    False   False  False\n",
              "2     False    False   False  False\n",
              "3     False    False   False  False\n",
              "4     False    False   False  False\n",
              "...     ...      ...     ...    ...\n",
              "5567  False    False   False  False\n",
              "5568  False    False   False  False\n",
              "5569  False    False   False  False\n",
              "5570  False    False   False  False\n",
              "5571  False    False   False  False\n",
              "\n",
              "[5572 rows x 4 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKE4JJhI_0OY",
        "outputId": "dd83a039-2b69-45fc-f9ad-db91581df72f"
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ham     4825\n",
              "spam     747\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMZzBapYAUBZ"
      },
      "source": [
        "# Text Feature Extraction\r\n",
        "# Import the package\r\n",
        "\r\n",
        "#Spliting the dataset into Training set and Test Set\r\n",
        "from sklearn.model_selection import train_test_split\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuzhxUSFYhC_"
      },
      "source": [
        "X = df['message']\r\n",
        "y = df['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLEh1HOcX7la"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOE89zHkHGo4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QCqiSBGHHhc"
      },
      "source": [
        "#**Scikit-learn's CountVectorizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTNXVYDiHMfp"
      },
      "source": [
        "'''Text preprocessing, tokenizing and the ability to filter out stopwords are all included in CountVectorizer, \r\n",
        "which builds a dictionary of features and transforms documents to feature vectors.'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1MOXZ6CX7xQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee63a79e-59a7-499b-8ba0-5538d3e7746f"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "count_vect = CountVectorizer()\r\n",
        "\r\n",
        "X_train_counts = count_vect.fit_transform(X_train)\r\n",
        "X_train_counts.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3733, 7082)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7yQ1SSBX76D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkwOEClEfi38",
        "outputId": "6fa91449-2808-46cc-90b8-2e320db68744"
      },
      "source": [
        "# Print the raw text format\r\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       Go until jurong point, crazy.. Available only ...\n",
              "1                           Ok lar... Joking wif u oni...\n",
              "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3       U dun say so early hor... U c already then say...\n",
              "4       Nah I don't think he goes to usf, he lives aro...\n",
              "                              ...                        \n",
              "5567    This is the 2nd time we have tried 2 contact u...\n",
              "5568                 Will ü b going to esplanade fr home?\n",
              "5569    Pity, * was in mood for that. So...any other s...\n",
              "5570    The guy did some bitching but I acted like i'd...\n",
              "5571                           Rofl. Its true to its name\n",
              "Name: message, Length: 5572, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55H35R9mk6zI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQk9ojIHX8Cd"
      },
      "source": [
        "\r\n",
        "# FIT VECTORIZATION TO THE DATA (build a vocab,count the number of words..)\r\n",
        "#count_vect.fit(X_train)#basically fit by translation\r\n",
        "#X_train_counts = count_vect.transform(X_train) # fit by transform\r\n",
        "# TRANSFORM THE ORIGINAL TEXT MESSAGE ---> VECTOR\r\n",
        "\r\n",
        "X_train_counts = count_vect.fit_transform(X_train)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KQM0gQXX8KT",
        "outputId": "031a4b5e-be68-4d1d-f2fd-75d9a52cd836"
      },
      "source": [
        "X_train_counts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<3733x7082 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 49992 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEZJD01mX8R5",
        "outputId": "48980819-8f5c-4bdd-ee88-5bd73ea29b80"
      },
      "source": [
        "X_train.shape\r\n",
        "\r\n",
        "#Total message count message is 3733\r\n",
        "# And the total vocab count is 7082\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3733,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8La59UoX8ZB",
        "outputId": "84e0e186-f37f-422b-c53b-3b0125390981"
      },
      "source": [
        "X_train_counts.shape\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3733, 7082)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ4eEa7rw1aq"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a95EiZ0uw42r"
      },
      "source": [
        "tfidf_transformer = TfidfTransformer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73tzabXYw5EY"
      },
      "source": [
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzSDo6Tmzltr",
        "outputId": "f00d6702-4036-4876-e579-0ed74f966045"
      },
      "source": [
        "X_train_tfidf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<3733x7082 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 49992 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZDYA4nuw5Qe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4522a33-376b-4d3f-e120-f963fc8c6cee"
      },
      "source": [
        "X_train_tfidf.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3733, 7082)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p7OJJykw5ct"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "vectorizer =TfidfVectorizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0gHbw9f5anN"
      },
      "source": [
        "X_train_tfidf = vectorizer.fit_transform(X_train)# this is originally x train data set "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Arn6ialnG_dN"
      },
      "source": [
        "#Train a classifier (import linear support vector classfier)\r\n",
        "from sklearn.svm import LinearSVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC2xqHjNG_v9",
        "outputId": "6f02c3f6-7765-4901-a493-636ae007c0d8"
      },
      "source": [
        "clf = LinearSVC()#clf means classifier\r\n",
        "clf.fit(X_train_tfidf,y_train)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaGubh87G_9y"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\r\n",
        "# so pipeline is using the natural language processing , stop words and vocabulary finding\r\n",
        "#linersvc means classification of the next step"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6LaSNUGI48M"
      },
      "source": [
        "text_clf = Pipeline([('tfidf',TfidfVectorizer()),('clf',LinearSVC())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alERyesXI5LP",
        "outputId": "d67ab050-e7df-4769-f955-ac8f26ce64a3"
      },
      "source": [
        "text_clf.fit(X_train,y_train)#print original raw text data (X train and y train)\r\n",
        "#print the text classification"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
              "                           fit_intercept=True, intercept_scaling=1,\n",
              "                           loss='squared_hinge', max_iter=1000,\n",
              "                           multi_class='ovr', penalty='l2', random_state=None,\n",
              "                           tol=0.0001, verbose=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48B3AxFmI5aN"
      },
      "source": [
        "predictions = text_clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtW4zzCL4UAu",
        "outputId": "62f6d82b-ec9c-4497-c8a8-b96ff6fc943d"
      },
      "source": [
        "X_test\r\n",
        "#these below output is raw text messages\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3245    Squeeeeeze!! This is christmas hug.. If u lik ...\n",
              "944     And also I've sorta blown him off a couple tim...\n",
              "1044    Mmm thats better now i got a roast down me! i...\n",
              "2484        Mm have some kanji dont eat anything heavy ok\n",
              "812     So there's a ring that comes with the guys cos...\n",
              "                              ...                        \n",
              "4944    Check mail.i have mailed varma and kept copy t...\n",
              "3313    I know you are serving. I mean what are you do...\n",
              "3652         Want to send me a virtual hug?... I need one\n",
              "14                    I HAVE A DATE ON SUNDAY WITH WILL!!\n",
              "4758    hey, looks like I was wrong and one of the kap...\n",
              "Name: sms, Length: 1839, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PO8S3DfLCSi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c95eb4ef-7342-4cc0-aa67-a6cd0b9067e8"
      },
      "source": [
        "# import matrix packages\r\n",
        "from sklearn.metrics import confusion_matrix,classification_report\r\n",
        "print(confusion_matrix(y_test,predictions))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1586    7]\n",
            " [  12  234]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChjN_7EnMRot",
        "outputId": "8221cf13-1368-4af3-cc2a-6e2f33336c59"
      },
      "source": [
        "print(confusion_matrix(y_test,predictions))\r\n",
        "# And performing much much better"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1586    7]\n",
            " [  12  234]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AE9CcATdI5kx",
        "outputId": "2df6d963-162e-4b08-f097-b26a9fc24eb4"
      },
      "source": [
        "print(classification_report(y_test,predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      1.00      0.99      1593\n",
            "        spam       0.97      0.95      0.96       246\n",
            "\n",
            "    accuracy                           0.99      1839\n",
            "   macro avg       0.98      0.97      0.98      1839\n",
            "weighted avg       0.99      0.99      0.99      1839\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7rZsG5TI5xn"
      },
      "source": [
        "# Now checkout accuracy of classifier\r\n",
        "from sklearn import metrics\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W63Cr3e_OUCv",
        "outputId": "d9f5a572-3d77-4891-e427-f61e1849d93d"
      },
      "source": [
        "metrics.accuracy_score(y_test,predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.989668297988037"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY8A4Ff0OUYN"
      },
      "source": [
        "#If you are print the new messages then "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikGM9oFxOUhC",
        "outputId": "219a0a7d-2aa1-4c0c-c06c-ac81af639404"
      },
      "source": [
        "text_clf.predict([\"Hi how are you doing today?\"])# so it means given input data is predicted then message is spam or fake message then message is showing ham"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ham'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuaKv39dPRb-",
        "outputId": "b2b70cbb-2d94-4e0c-8fbc-3a78c0e7c4d2"
      },
      "source": [
        "text_clf.predict([\"Congratulations! you have to selected as a winner.Text Won to 44255 congratulations free entry to contest.\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['spam'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMZBopAGOUqI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}